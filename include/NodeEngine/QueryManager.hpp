/*
    Copyright (C) 2020 by the NebulaStream project (https://nebula.stream)

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        https://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.
*/

#ifndef INCLUDE_QUERY_MANAGER_HPP_
#define INCLUDE_QUERY_MANAGER_HPP_

#include <NodeEngine/BufferManager.hpp>
#include <NodeEngine/Execution/ExecutableQueryPlanStatus.hpp>
#include <NodeEngine/NodeEngineForwaredRefs.hpp>
#include <NodeEngine/QueryStatistics.hpp>
#include <NodeEngine/Reconfigurable.hpp>
#include <NodeEngine/ReconfigurationMessage.hpp>
#include <NodeEngine/Task.hpp>
#include <NodeEngine/ThreadPool.hpp>
#include <Phases/ConvertLogicalToPhysicalSource.hpp>
#include <Plans/Query/QuerySubPlanId.hpp>
#include <Sources/DataSource.hpp>
#include <Util/ThreadBarrier.hpp>
#include <Util/VirtualEnableSharedFromThis.hpp>
#include <Util/libcuckoo/cuckoohash_map.hh>
#include <Windowing/WindowHandler/AbstractWindowHandler.hpp>
#include <chrono>
#include <condition_variable>
#include <deque>
#include <map>
#include <memory>
#include <mutex>
#include <shared_mutex>
#include <thread>
#include <unordered_map>
#include <unordered_set>

#ifdef NES_USE_MPMC_BLOCKING_CONCURRENT_QUEUE
#include <folly/MPMCQueue.h>
#endif

namespace NES::NodeEngine {

/**
 * @brief the query manager is the central class to process queries.
 * It is source-driven. Each incoming buffer will add a task to the queue.
 * The query manager maintains three structures:
 * 1.) a data_source map to map one data source to N queries
 * 2.) a window map to map one window to N queries TODO:maybe should be removed later
 * 3.) a data_sink to map one data sink to N queries
 * @Limitations:
 *    - statistics do not cover intermediate buffers
 */
class QueryManager : public NES::detail::virtual_enable_shared_from_this<QueryManager>, public Reconfigurable {
    typedef NES::detail::virtual_enable_shared_from_this<QueryManager> inherited0;
    typedef Reconfigurable inherited1;

  public:
    QueryManager() = delete;
    QueryManager(const QueryManager&) = delete;
    QueryManager& operator=(const QueryManager&) = delete;

    /**
     * @brief
     * @param bufferManager
     */
    explicit QueryManager(BufferManagerPtr bufferManager, uint64_t nodeEngineId, uint16_t numThreads);

    ~QueryManager();

    /**
     * @brief register a query by extracting sources, windows and sink and add them to
     * respective map
     * @param QueryExecutionPlan to be deployed
     */
    bool registerQuery(Execution::ExecutableQueryPlanPtr qep);

    /**
     * @brief deregister a query by extracting sources, windows and sink and remove them
     * from respective map
     * @param QueryExecutionPlan to be deployed
     * @return bool indicating if register was successful
     */
    bool deregisterQuery(Execution::ExecutableQueryPlanPtr qep);

    /**
     * @brief process task from task queue
     * @param bool indicating if the thread pool is still running
     * @param worker context
     * @return an execution result
     *
     */
#ifndef NES_USE_MPMC_BLOCKING_CONCURRENT_QUEUE
    ExecutionResult processNextTask(std::atomic<bool>& running, WorkerContext& workerContext);
#else
    ExecutionResult processNextTask(bool running, WorkerContext& workerContext);
#endif

    /**
     * @brief add work to the query manager, this methods is source-driven and is called
     * for each incoming buffer
     * @param Pointer to the tuple buffer containing the data
     * @param Pointer to the source at which the data arrived
     */
    void addWork(const OperatorId operatorId, TupleBuffer& buf);

    /**
     * @brief add work to the query manager, this methods is source-driven and is called
     * for each buffer generated by the window trigger
     * @param Pointer to the tuple buffer containing the data
     * @param Pointer to the pipeline stage that will be executed next
     */
    void addWorkForNextPipeline(TupleBuffer& buffer, Execution::ExecutablePipelinePtr nextPipeline);

    void postReconfigurationCallback(ReconfigurationMessage& task) override;

    void reconfigure(ReconfigurationMessage&, WorkerContext& context) override;

    /**
     * @brief retrieve the execution status of a given local query sub plan id.
     * @param id : the query sub plan id
     * @return status of the query sub plan
     */
    Execution::ExecutableQueryPlanStatus getQepStatus(QuerySubPlanId id);

    /**
     * @brief get general statistics of QueryManager and Buffer Manager
     */
    std::string getQueryManagerStatistics();

    /**
     * @brief method to start a query
     * @param qep of the query to start
     * @return bool indicating success
     */
    bool startQuery(Execution::ExecutableQueryPlanPtr qep);

    /**
     * @brief method to start a query
     * @param qep of the query to start
     * @param graceful stop the query gracefully or not
     * @return bool indicating success
     */
    bool stopQuery(Execution::ExecutableQueryPlanPtr qep, bool graceful = false);

    /**
    * @brief method to fail a query
    * @param qep of the query to fail
    * @return bool indicating success
    */
    bool failQuery(Execution::ExecutableQueryPlanPtr qep);

    /**
     * @brief notify all waiting threads in getWork() to wake up and try again
     */
    void unblockThreads();

    /**
     * @brief reset query manager to intial state
     */
    void destroy();

    /**
     * @brief method to return the query statistics
     * @param qep of the particular query
     * @return
     */
    QueryStatisticsPtr getQueryStatistics(QuerySubPlanId qepId);

    uint64_t getNodeId() const;

    /**
     * @brief this methods adds a reconfiguration task on the worker queue
     * @return true if the reconfiguration task was added correctly on the worker queue
     * N.B.: this does not not mean that the reconfiguration took place but it means that it
     * was scheduled to be executed!
     * @param queryExecutionPlanId: the local QEP to reconfigure
     * @param reconfigurationDescriptor: what to do
     * @param blocking: whether to block until the reconfiguration is done. Mind this parameter because it blocks!
     */
    bool addReconfigurationMessage(QuerySubPlanId queryExecutionPlanId, ReconfigurationMessage reconfigurationMessage,
                                   bool blocking = false);

    /**
     * @brief introduces end of stream to all QEPs connected to this source
     * @param sourceId the id of the source
     * @param graceful hard or soft termination
     * @return true if it went through
     */
    bool addEndOfStream(OperatorId sourceId, bool graceful = true);

    /**
     * @return true if thread pool is running
     */
    bool isThreadPoolRunning() const;

    /**
     * @brief get number of tasks in the queue
     * @return task count
     */
    uint64_t getNumberOfTasksInWorkerQueue() const;

  private:
    friend class ThreadPool;
    friend class NodeEngine;
    /**
    * @brief method to start the thread pool
    * @param nodeEngineId the id of the owning node engine
    * @return bool indicating success
    */
    bool startThreadPool();

    /**
     * @brief finalize task execution by:
     * 1.) update statistics (number of processed tuples and tasks)
     * 2.) release input buffer (give back to the buffer manager)
     * @param reference to processed task
     * @oaram reference to worker context
     */
    void completedWork(Task& task, WorkerContext& workerContext);

    ExecutionResult terminateLoop(WorkerContext&);

    ThreadPoolPtr threadPool;

    std::map<OperatorId, std::unordered_set<Execution::ExecutableQueryPlanPtr>> operatorIdToQueryMap;
    std::map<OperatorId, std::vector<OperatorId>> queryMapToOperatorId;

    std::map<OperatorId, uint64_t> operatorIdToPipelineStage;

    std::unordered_map<QuerySubPlanId, Execution::ExecutableQueryPlanPtr> runningQEPs;

    //TODO:check if it would be better to put it in the thread context
    mutable std::mutex statisticsMutex;
    cuckoohash_map<QuerySubPlanId, QueryStatisticsPtr> queryToStatisticsMap;

    std::shared_mutex queryMutex;
#ifdef NES_USE_MPMC_BLOCKING_CONCURRENT_QUEUE
    folly::MPMCQueue<Task> taskQueue;
#else
    std::deque<Task> taskQueue;
    mutable std::mutex workMutex;
    std::condition_variable cv;
#endif
    BufferManagerPtr bufferManager;
    Execution::ExecutablePipelineStagePtr reconfigurationExecutable;

    uint64_t nodeEngineId;

    uint16_t numThreads;

    std::atomic<bool> isDestroyed;
};

typedef std::shared_ptr<QueryManager> QueryManagerPtr;

}// namespace NES::NodeEngine

#endif /* INCLUDE_query manager_H_ */
