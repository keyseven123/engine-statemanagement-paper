{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Monitoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tim/Documents/work/apache_flink\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path = os.getcwd()\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.common import Configuration\n",
    "from pyflink.table import TableEnvironment, EnvironmentSettings, DataTypes, TableDescriptor, Schema\n",
    "\n",
    "# Set up the execution configuration\n",
    "configuration = Configuration()\n",
    "configuration.set_integer(\"table.exec.resource.default-parallelism\", 1)\n",
    "\n",
    "# Create the TableEnvironment in streaming mode\n",
    "t_env = TableEnvironment.create(\n",
    "    EnvironmentSettings.new_instance().in_streaming_mode().with_configuration(configuration).build()\n",
    ")\n",
    "\n",
    "# Create a temporary table for the monitoring data\n",
    "monitoring_table = t_env.create_temporary_table(\n",
    "    'monitoring',\n",
    "    TableDescriptor.for_connector('filesystem')\n",
    "    .schema(\n",
    "        Schema.new_builder()\n",
    "            .column('creationTS', DataTypes.BIGINT())\n",
    "            .column('jobId', DataTypes.BIGINT())\n",
    "            .column('taskId', DataTypes.BIGINT())\n",
    "            .column('machineId', DataTypes.BIGINT())\n",
    "            .column('eventType', DataTypes.SMALLINT())\n",
    "            .column('userId', DataTypes.SMALLINT())\n",
    "            .column('category', DataTypes.SMALLINT())\n",
    "            .column('priority', DataTypes.SMALLINT())\n",
    "            .column('cpu', DataTypes.FLOAT())\n",
    "            .column('ram', DataTypes.FLOAT())\n",
    "            .column('disk', DataTypes.FLOAT())\n",
    "            .column('constraints', DataTypes.SMALLINT())\n",
    "            .column_by_expression('eventTime', \"TO_TIMESTAMP_LTZ(creationTS, 3)\")\n",
    "            .watermark('eventTime', \"eventTime\")\n",
    "            .build()\n",
    "    )\n",
    "    .option('path', f'{base_path}/data/cluster_monitoring/google-cluster-data.csv')\n",
    "    .format('csv')\n",
    "    .build()\n",
    ")\n",
    "\n",
    "t_env.create_temporary_table(\n",
    "    'sink_q1',\n",
    "    TableDescriptor.for_connector('filesystem')\n",
    "    .schema(Schema.new_builder()\n",
    "            .column('totalCpu', DataTypes.FLOAT())\n",
    "            .column('window_start', DataTypes.BIGINT())\n",
    "            .column('window_end', DataTypes.BIGINT())\n",
    "            .build())\n",
    "    .option('path', f'{base_path}/data/cluster_monitoring/outputs/sink_q1.csv')\n",
    "    .format('csv')\n",
    "    .build()\n",
    ")\n",
    "\n",
    "t_env.create_temporary_table(\n",
    "    'sink_q2',\n",
    "    TableDescriptor.for_connector('filesystem')\n",
    "    .schema(\n",
    "       Schema.new_builder()\n",
    "           .column('jobId', DataTypes.BIGINT())\n",
    "           .column('totalCpu', DataTypes.FLOAT())\n",
    "           .column('window_start', DataTypes.BIGINT())\n",
    "           .column('window_end', DataTypes.BIGINT())\n",
    "           .build()\n",
    "    )\n",
    "    .option('path', f'{base_path}/data/cluster_monitoring/outputs/sink_q2.csv')\n",
    "    .format('csv')\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1 \n",
    "\n",
    "```cpp\n",
    "Query::from(\"cm\")\n",
    "    .window(SlidingWindow::of(EventTime(RecordCreationTs()), Seconds(60), Seconds(1)))\n",
    "    .apply(Sum(Attribute(\"cpu\"))->as(Attribute(\"totalCpu\")))\n",
    "    .sink(NullOutputSinkDescriptor::create());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "INSERT INTO sink_q1\n",
    "SELECT \n",
    "    SUM(cpu) AS totalCpu,\n",
    "    1000 * UNIX_TIMESTAMP(CAST(window_start AS STRING)) + EXTRACT(MILLISECOND FROM window_start) as `window_start`,\n",
    "    1000 * UNIX_TIMESTAMP(CAST(window_end AS STRING)) + EXTRACT(MILLISECOND FROM window_end) as `window_end`\n",
    "FROM TABLE(\n",
    "    HOP(\n",
    "        TABLE monitoring,\n",
    "        DESCRIPTOR(eventTime),\n",
    "        INTERVAL '1' SECOND,  -- slide interval\n",
    "        INTERVAL '60' SECOND  -- window size\n",
    "    )\n",
    ")\n",
    "GROUP BY window_start, window_end\n",
    "\"\"\").wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2 \n",
    "```cpp\n",
    "Query::from(\"cm\")\n",
    "    .filter(Attribute(\"eventType\") == 3)\n",
    "    .window(SlidingWindow::of(EventTime(RecordCreationTs()), Seconds(60), Seconds(1)))\n",
    "    .byKey(Attribute(\"jobId\"))\n",
    "    .apply(Sum(Attribute(\"cpu\"))->as(Attribute(\"totalCpu\")))\n",
    "    .sink(NullOutputSinkDescriptor::create());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to split the query into 2 seperate once since Flink SQL does not support writing subqueries directly in the Table HOP call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7fdb8d92b490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "CREATE TEMPORARY VIEW filtered_monitoring AS\n",
    "SELECT *\n",
    "FROM monitoring\n",
    "WHERE eventType = 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_env.execute_sql(\"\"\"\n",
    "INSERT INTO sink_q2\n",
    "SELECT \n",
    "    jobId,\n",
    "    SUM(cpu) AS totalCpu,\n",
    "    1000 * UNIX_TIMESTAMP(CAST(window_start AS STRING)) + EXTRACT(MILLISECOND FROM window_start) as `window_start`,\n",
    "    1000 * UNIX_TIMESTAMP(CAST(window_end AS STRING)) + EXTRACT(MILLISECOND FROM window_end) as `window_end`\n",
    "FROM TABLE(\n",
    "    HOP(\n",
    "        TABLE filtered_monitoring,\n",
    "        DESCRIPTOR(eventTime),\n",
    "        INTERVAL '1' SECOND,  -- slide interval\n",
    "        INTERVAL '60' SECOND  -- window size\n",
    "    )\n",
    ")\n",
    "GROUP BY jobId, window_start, window_end\n",
    "\"\"\").wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformat data input from txt to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define your base path and file paths\n",
    "base_path = '/home/tim/Documents/work/apache_flink'\n",
    "input_file = os.path.join(base_path, 'data/cluster_monitoring/google-cluster-data.txt')\n",
    "output_file = os.path.join(base_path, 'data/cluster_monitoring/google-cluster-data.csv')\n",
    "\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for line in infile:\n",
    "        # Split on any whitespace and filter out any empty strings\n",
    "        row = line.strip().split()\n",
    "        if len(row) == 12:  # Optionally, ensure the correct number of columns\n",
    "            writer.writerow(row)\n",
    "        else:\n",
    "            print(\"Skipping line due to incorrect number of columns:\", line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
