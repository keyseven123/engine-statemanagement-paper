# How to add a `Source`

Sources in NebulaStream have the task of ingesting data into the system.
Usually, they connect to the outside world by through some communication channel.
This means interacting with some hardware by using a client library, kernel API, or the like.
Examples of sources could include:

- File
- TCP
- MQTT
- Kafka
- PostgreSQL
- Serial Port

Some of these examples are external software systems, other are networking protocols, others hardware devices.

Most of the time, a source will wrap a client library to interact with the data source we want to connect to and read data from.
For this guide, we'll use the `MQTTSource`, which allows reading data from an MQTT broker via the MQTT network protocol.

## 1. Overview

In `nes-plugins`, we find the implementations of existing plugins.
We create a directory `MQTTSource` where we put our implementation.
Generally, you can structure this however you see fit and describe the resulting structure in the `CMakeLists.txt`.
In our example, we will use one header and .cpp file for the MQTT source.

```
nes-plugins/
├── Sources/
│   ├── MQTTSource/
│   │   ├── MQTTSource.hpp
│   │   ├── MQTTSource.cpp
│   │   ├── CMakeLists.txt
│   │   └── ...
│   ├── KafkaSource/
│   └── ...
├── Sinks/
├── Functions/
└── ...
```

## 2. Dependencies & CMake

In the `CMakeLists.txt` file of our directory, we tell cmake how we want our plugin to be built:

```cmake
find_package(PahoMqttCpp CONFIG REQUIRED) # <-- We depend on the paho-mqtt lib

# 1) Source Plugin
add_plugin_as_library(
        MQTT                       # Plugin name
        Source                     # Component name  
        nes-sources-registry       # Component registry name
        mqtt-source-plugin-library # Plugin library name
        MQTTSource.cpp             # Source files list
)
target_include_directories(mqtt-source-plugin-library
        PUBLIC include
        PRIVATE .
)
target_link_libraries(mqtt-source-plugin-library PRIVATE PahoMqttCpp::paho-mqttpp3-static)

# 2) Source Validation Plugin
add_plugin_as_library(MQTT SourceValidation nes-sources-registry mqtt-source-validation-plugin-library MQTTSource.cpp)
target_include_directories(mqtt-source-validation-plugin-library
        PUBLIC include
        PRIVATE .
)
target_link_libraries(mqtt-source-validation-plugin-library PRIVATE PahoMqttCpp::paho-mqttpp3-static)
```

We need to add two different plugins, the source plugin (1) and the source validation plugin (2).
Both plugins will be compiled into a library that is linked against the source registry.
Upon activation of the plugins, cmake will generate a `Registrar` type each, which passes the creation function (source plugin) or validation function (validation plugin) for our `MQTTSource` to the source registry.
We will look into the creation/validation more closely in the next chapter.
For now, it suffices to know that this function will add our plugins as a library to the build when activated.
We are allowed to choose the plugin library name freely, the component name and the component registry name are fixed though.
We specify all necessary include paths and link our library against its dependencies (if any).
If a dependency is not included in our `vcpkg/vcpkg.json`, we need to build and install the dependency here (e.g.,
using `FetchContent`).

## 3. Creation & Validation
During lowering of a query plan that uses an source, NebulaStream will ask the `SourceRegistry` for an instance of our source through the mentioned **creation function**.
It looks like this:
```c++
using SourceRegistryReturnType = std::unique_ptr<Source>;

SourceRegistryReturnType SourceGeneratedRegistrar::RegisterMQTTSource(SourceRegistryArguments sourceRegistryArguments)
{
    return std::make_unique<MQTTSource>(sourceRegistryArguments.sourceDescriptor);
}
```
The creation function is associated with the registrar type generated by cmake during the build and is given to the registry.
Currently, sources should define at least a single constructor that takes an argument of type `SourceDescriptor`.
A `SourceDescriptor` fully describes a physical source.
At its heart, there is `DescriptorConfig` that we use to store all parameters to fully specify a source.
The configuration maps the name of the parameter to a `std::variant` of all types that we allow as values for config parameters:
```c++
using ConfigType = std::variant<
    int32_t,
    uint32_t,
    int64_t,
    uint64_t,
    bool,
    char,
    float,
    double,
    std::string,
    EnumWrapper,
    FunctionList,
    AggregationFunctionList,
    WindowInfos>;
using Config = std::unordered_map<std::string, ConfigType>;
```
The configuration can be used in the constructor in the following way to initialize member variables:
```c++
MQTTSource::MQTTSource(const SourceDescriptor& sourceDescriptor)
    : serverUri(sourceDescriptor.getFromConfig(ConfigParametersMQTT::SERVER_URI))
    , clientId(sourceDescriptor.getFromConfig(ConfigParametersMQTT::CLIENT_ID))
    , topic(sourceDescriptor.getFromConfig(ConfigParametersMQTT::TOPIC))
    , qos(sourceDescriptor.getFromConfig(ConfigParametersMQTT::QOS))
    /// ...other parameters    
{
}
```
The `getFromConfig` method of the descriptor fetches the relevant values for the parameters.
At the point of the construction of the source, we expect that all mandatory parameters exist in the config and contain valid values or sensible defaults of the correct types.
In order to give this guarantee, during query planning, we have a validation phase that will fail in the presence of any wrong or missing parameters.
```c++
Configurations::DescriptorConfig::Config MQTTSource::validateAndFormat(std::unordered_map<std::string, std::string> config)
{
    return Configurations::DescriptorConfig::validateAndFormat<ConfigParametersMQTT>(std::move(config), NAME);
}

Configurations::DescriptorConfig::Config;
SourceValidationGeneratedRegistrar::RegisterMQTTSourceValidation(SourceValidationRegistryArguments sourceConfig)
{
    return MQTTSource::validateAndFormat(std::move(sourceConfig.config));
}
```

This validation function will be registered in the mentioned validation plugin.
It takes an `std::unordered_map<std::string, std::string>` and is expected to:
- Lookup each parameter name to check if it has been supplied by the user 
- If it does not exist, either report an error or supply a sensible default
- Parse the string into the correct type expected by the source
- Check its validity, e.g., a port needs to be a valid `uint16_t`

## 4. Implementation

The interface to implement a source is straightforward:

```c++
/// Read data into a `TupleBuffer`, until the TupleBuffer is full, or stop was requested.
/// @return the number of bytes read
virtual size_t fillTupleBuffer(NES::Memory::TupleBuffer& tupleBuffer, const std::stop_token& stopToken) = 0;

 /// If applicable, opens resources like file descriptors, database connections, etc.
virtual void open() = 0;

/// If applicable, closes resources like file descriptors, database connections, etc.
virtual void close() = 0;
```

The central method we need to implement is called `fillTupleBuffer`, which takes a reference to a buffer and a `stop_token`.
It should implement the necessary logic to ingest data into the buffer.
`fillTupleBuffer` will never be called with the same buffer twice; therefore it is always safe to write to the beginning
of the buffer's memory.

We return from this function in either of four cases:
1. An error internal to our source happens, e.g., a file does not exist
2. The `stop_token` indicates stop has been requested from a higher-level component (e.g., the query was stopped)
3. We have received an "end of stream" (EOS) signal
4. The buffer has been filled to its capacity

In case (1), we can decide whether the error is recoverable or unrecoverable, and either try again or throw an
exception.
When stop has been requested (2), we should return, signalling the number of bytes read so far.
In order to be responsive to possible stop requests, we should check the `stop_token` regularly, if possible.
(3) indicates an EOS signal (e.g., a terminated connection) and it means that we do not expect any further data, which
we report by returning 0.
Finally, if buffer has been filled entirely (4), we should also return, reporting the buffer size as the number of read
bytes.

The `open` and `close` methods can be used to create or release resources like file descriptors.
`open` will be called once before the first invocation to `fillTupleBuffer`, `close` likewise at the end, before
dropping the source.

For our MQTT source, `open` might look like this:
```c++
void MQTTSource::open()
{
    client = std::make_unique<mqtt::client>(serverURI, clientId);
    try
    {
        const auto connectOptions = mqtt::connect_options_builder().automatic_reconnect(true).clean_session(false).finalize();
        client->start_consuming();

        const auto token = client->connect(connectOptions);
        if (const auto response = token->get_connect_response(); !response.is_session_present())
        {
            client->subscribe(topic, qos)->wait();
        }
    }
    catch (const mqtt::exception& e)
    {
        throw CannotOpenSource("Could not connect to MQTT broker: {}", e.what());
    }
}
```

In short, we instantiate an MQTT client through which we can interact with a broker, passing necessary information.
Then, we try to establish a session and subscribe to a topic, indicating that we are ready to start consuming data.
If the client throws any exception, we rethrow a `CannotOpenSource` exception.
Similarly, close can be implemented: 
```c++
void MQTTSource::close() try 
{
    client->unsubscribe(topic)->wait();
    client->disconnect()->wait();
} 
catch (const mqtt::exception& e)
{
    NES_ERROR("Error on close: {}", e.what());
}
```
Because no methods of the `MQTTSource` will be called after `close`, we simply report any MQTT-related error closing the session and return.

`fillTupleBuffer` will, in most scenarios, be implemented I/O requests in a loop until either the buffer is filled entirely, or an error occurs or EOS is signalled.
```c++
size_t MQTTSource::fillTupleBuffer(NES::Memory::TupleBuffer& buf, const std::stop_token& stopToken)
{
    /// (1) Setup offset within buffer, size of buffer, timestamp of next flush
    size_t offset = 0;
    const size_t size = tupleBuffer.getBufferSize();
    auto nextFlush = std::chrono::system_clock::now() + std::chrono::milliseconds(flushInterval);

    /// (2) Process stashed payload first (from prior invocation of `fillTupleBuffer`)
    if (!payloadStash.empty())
    {
        auto payload = payloadStash.consume(size);
        writePayloadToBuffer(payload, buf, offset);
    }

    /// (3) Fill buffer with new messages until full, timeout, or Error/EoS
    while (offset < size && !stopToken.stop_requested()) /// <-- if stop requested, end loop
    {
        /// (4) Check timeout, if passed either set new timeout or emit buffer
        if (nextFlush < std::chrono::system_clock::now())
        {
            if (offset == 0) /// <-- no data read since last flush
                nextFlush = std::chrono::system_clock::now() + std::chrono::milliseconds(flushInterval);
            else
                return offset; /// <-- flush preemptively
        }

        if (auto& message = client->try_consume_message_until(nextFlush); message) 
            writePayloadToBuffer(message->get_payload(), buf, offset); /// <-- message received within timeout
    }
    return std::min(offset, size);
}
```
In our example, an additional flushing interval is specified to prematurely return buffers for lower latency.
Furthermore, this specific MQTT client library allocates its own receive buffer for incoming data.
This possibly results in larger messages than currently available space in our buffer.
To handle such a case, we stash intermediate data until the next invocation of `fillTupleBuffer`, where it is consumed before making another consume request.
When errors occur during ingestion, the client will throw an exception, which is handled in a higher-level component.
If you want to handle an error that is recoverable, you should catch the exception in this method and call any code required for recovery.

## 5. Testing

